<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Posts by Rito Ghosh - CV</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Posts by Rito Ghosh</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./TILs_index.html" rel="" target="">
 <span class="menu-text">TILs</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./now.html" rel="" target="">
 <span class="menu-text">Now</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./cv.html" rel="" target="" aria-current="page">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./publications.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/ritog" rel="" target="">
 <span class="menu-text"><iconify-icon role="img" inline="" icon="fa6-brands:github" aria-label="Icon github from fa6-brands Iconify.design set." title="Icon github from fa6-brands Iconify.design set."></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://twitter.com/AllesistKode" rel="" target="">
 <span class="menu-text"><iconify-icon role="img" inline="" icon="fa6-brands:twitter" aria-label="Icon twitter from fa6-brands Iconify.design set." title="Icon twitter from fa6-brands Iconify.design set."></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=R_X74h0AAAAJ" rel="" target="">
 <span class="menu-text"><iconify-icon role="img" inline="" icon="fa6-brands:google-scholar" aria-label="Icon google-scholar from fa6-brands Iconify.design set." title="Icon google-scholar from fa6-brands Iconify.design set."></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://sigmoid.social/@rito" rel="me" target="">
 <span class="menu-text"><iconify-icon role="img" inline="" icon="fa6-brands:mastodon" aria-label="Icon mastodon from fa6-brands Iconify.design set." title="Icon mastodon from fa6-brands Iconify.design set."></iconify-icon></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://linkedin.com/in/ritobrata-ghosh" rel="" target="">
 <span class="menu-text"><iconify-icon role="img" inline="" icon="fa6-brands:linkedin" aria-label="Icon linkedin from fa6-brands Iconify.design set." title="Icon linkedin from fa6-brands Iconify.design set."></iconify-icon></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="./index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<div class="quarto-about-jolla">
  <img src="self.png" class="about-image
  round " style="height: 15em; width: 15em;">
 <header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">CV</h1>
</div>
<div class="quarto-title-meta">
  </div>
</header><main class="content" id="quarto-document-content">
<section id="rito-ghosh" class="level1">
<h1>Rito Ghosh</h1>
<section id="legal-name-ritobrata-ghosh" class="level4">
<h4 data-anchor-id="legal-name-ritobrata-ghosh"><em>Legal name:</em> Ritobrata Ghosh</h4>
</section>
<section id="hehim" class="level4">
<h4 data-anchor-id="hehim">(he/him)</h4>
<p><img src="self.png" height="150" width="150"></p>
<hr>
<section id="google-scholar-visit-blog-visit-linkedin-for-a-more-updated-version-twitter-github-mastodon-gh_uname.mlgmail.com-cv" class="level5">
<h5 data-anchor-id="google-scholar-visit-blog-visit-linkedin-for-a-more-updated-version-twitter-github-mastodon-gh_uname.mlgmail.com-cv"><a href="https://scholar.google.com/citations?user=R_X74h0AAAAJ">Google Scholar 🎓</a> | Visit <a href="https://ritog.github.io/blog">📄 Blog</a> | Visit <a href="https://linkedin.com/in/ritobrata-ghosh">LinkedIn</a> for a more updated version | <a href="https://twitter.com/AllesistKode">✖️/Twitter</a> | <a href="https://github.com/ritog">😸 GitHub</a> | <a rel="me" href="https://sigmoid.social/@rito"> 🐘 Mastodon</a> | ✉️ [gh_uname].ml@gmail.com | <a href="Ritobrata_Ghosh_CV.pdf">📃 CV</a></h5>
<hr>
</section>
</section>
<section id="research-interests-computer-vision-scientific-machine-learning-artificial-life-edge-aitinyml-computational-neuroscience-efficient-nlp." class="level4">
<h4 data-anchor-id="research-interests-computer-vision-scientific-machine-learning-artificial-life-edge-aitinyml-computational-neuroscience-efficient-nlp.">🥼 <strong><em>Research Interests</em></strong>: Computer Vision, Scientific Machine Learning, Artificial Life, Edge AI/TinyML, Computational Neuroscience, Efficient NLP.</h4>
</section>
<section id="key-skills-python-deep-learning-machine-learning-computer-vision-pytorch-mathematics-programming-team-work-communication." class="level4">
<h4 data-anchor-id="key-skills-python-deep-learning-machine-learning-computer-vision-pytorch-mathematics-programming-team-work-communication.">🗝️ <strong><em>Key Skills</em></strong>: Python, Deep Learning, Machine Learning, Computer Vision, PyTorch, Mathematics, Programming, Team Work, Communication.</h4>
<hr>
</section>
<section id="experience" class="level2">
<h2 data-anchor-id="experience">👨‍💻 Experience</h2>
<section id="deep-learning-research-consultant---akbar-brothers" class="level4">
<h4 data-anchor-id="deep-learning-research-consultant---akbar-brothers">🟦 Deep Learning Research Consultant - Akbar Brothers</h4>
<section id="mar-2021---jun-2023-remote" class="level5">
<h5 data-anchor-id="mar-2021---jun-2023-remote">🗓️ Mar 2021 - Jun 2023 | 🗺️ Remote</h5>
<ul>
<li>Worked in single-label classification with many labels.</li>
<li>Cleaned, wrangled a large amount of data (&gt;60 GB).</li>
<li>Set up end-to-end Deep Learning training pipeline for single-label image classification.</li>
<li>Experimented and worked with Deep Learning architectures such as DenseNet, ResNet, EfficientNet</li>
<li>Used improvement techniques such as image data augmentation, oversampling and undersampling, gradual freezing, discriminative learning rates, ensemble methods, etc.</li>
<li>Achieved accuracy of &gt;91% in the classification task, where this has never been done before.</li>
<li>Worked with tabular data of ~200k rows involving features to predict numerical data with XGBoost. Achieved ~98% accuracy.</li>
<li>Worked closely with business stakeholders to understand and solve problems.</li>
<li>Stack: Python, PyTorch, fast.ai, Scikit-Learn, XGBoost, Pandas, Python, Colab Pro.</li>
</ul>
<p><strong>Skills</strong>: Machine Learning, Deep Learning, Python (Programming Language), Data Science, Programming, Computer Vision, Linux, Jupyter Notebook, PyTorch, Written Communication, Convolutional Neural Networks (CNN)</p>
</section>
</section>
<section id="deep-learning-research-consultant---okkular.io" class="level4">
<h4 data-anchor-id="deep-learning-research-consultant---okkular.io">🟦 Deep Learning Research Consultant - Okkular.io</h4>
<section id="sep-2021---oct-2021-remote" class="level5">
<h5 data-anchor-id="sep-2021---oct-2021-remote">🗓️ Sep 2021 - Oct 2021 | 🗺️ Remote</h5>
<ul>
<li>Wrote the patent filing for a novel architecture developed inside the company (filing process ongoing)</li>
<li>Briefly worked on Active Learning techniques in Computer Vision to automate the training process and improve accuracy and maintenance.</li>
<li>Stack: Python, PyTorch, fast.ai, AWS SageMaker, AWS S3, Pandas.</li>
</ul>
<p><strong>Skills</strong>: Deep Learning, Linux, AWS SageMaker, Team Work</p>
</section>
</section>
<section id="technical-reviewer---packt" class="level4">
<h4 data-anchor-id="technical-reviewer---packt">🟦 Technical Reviewer - Packt</h4>
<section id="sep-2022---present-remote" class="level5">
<h5 data-anchor-id="sep-2022---present-remote">🗓️ Sep 2022 - Present | 🗺️ Remote</h5>
<ul>
<li>Reviewing a book on Advanced PyTorch. Chapters include: multimodal AI, Deep Reinforcement Learning, etc.</li>
<li>Working with co-ordinators and other editors.</li>
</ul>
<p><strong>Skills</strong>: PyTorch, Computer Vision, NLP, Reinforcement Learning, Team Work</p>
</section>
</section>
<section id="section-leader-teaching-assistant-of-code-in-place-programme---stanford-university" class="level4">
<h4 data-anchor-id="section-leader-teaching-assistant-of-code-in-place-programme---stanford-university">🟦 Section Leader (Teaching Assistant) of Code in Place Programme - Stanford University</h4>
<section id="apr-2021---jun-2021-remote" class="level5">
<h5 data-anchor-id="apr-2021---jun-2021-remote">🗓️ Apr 2021 - Jun 2021| 🗺️ Remote</h5>
<ul>
<li><p>This online course was offered by Stanford University during the COVID-19 pandemic. It brought together 12,000 students and 1,100 volunteer teachers participating from around the world. The course is a 6-week introduction to Python programming using materials from the first half of Stanford’s CS106A course.</p></li>
<li><p>As a volunteer section leader, I prepared and taught a weekly discussion section of 8-10 students to supplement professors’ lectures.</p></li>
<li><p>Received direct training from Stanford Professors Mehran Sahami, Chris Piech, and Julie Zelenski. Received further training from Stanford-appointed teacher mentors.</p></li>
<li><p>Taught introductory Python and CS to about 12 students from India, Bangladesh, and the USA. Students were of various ages and came from diverse backgrounds including from Fine Arts backgrounds. For many students, it was the first introduction to programming and CS ever.</p></li>
<li><p>Taught five sessions of my own (lasting 1.5 h on average) and a backup session for another.</p></li>
<li><p>Taught programming, problem-solving, and CS concepts.</p></li>
</ul>
<p><strong>Skills</strong>: Python, Programming, Teaching, Team Work</p>
<hr>
</section>
</section>
</section>
<section id="education" class="level2">
<h2 data-anchor-id="education">👨‍🏫 Education</h2>
<section id="master-of-science-computer-science-m.sc.-cs" class="level3">
<h3 data-anchor-id="master-of-science-computer-science-m.sc.-cs">🟩 Master of Science (Computer Science) [M.Sc. (CS)]</h3>
<section id="techno-college-hooghly-under-makaut-jul-2021---jul-2023-kolkata" class="level4">
<h4 data-anchor-id="techno-college-hooghly-under-makaut-jul-2021---jul-2023-kolkata">🏛️ Techno College Hooghly (under <a href="https://makautwb.ac.in/">MAKAUT</a>) | 🗓️ Jul 2021 - Jul 2023 | 🗺️ Kolkata</h4>
<p><strong>CGPA: 9.04/10</strong> Notable courses: Advanced algorithms, Soft Computing, Artificial Intelligence</p>
</section>
</section>
<section id="bachelor-of-science-physics-mathematics-computer-science-b.sc." class="level3">
<h3 data-anchor-id="bachelor-of-science-physics-mathematics-computer-science-b.sc.">🟩 Bachelor of Science (Physics, Mathematics, Computer Science) [B.Sc.]</h3>
<section id="university-of-calcutta-jul-2017---apr-2021-kolkata" class="level4">
<h4 data-anchor-id="university-of-calcutta-jul-2017---apr-2021-kolkata">🏛️ University of Calcutta | 🗓️ Jul 2017 - Apr 2021 | 🗺️ Kolkata</h4>
<p><strong>Grade: First Class</strong> Notable courses: Mathematical Methods for Physics I, II, Quantum Mechanics, Statistical Mechanics, Special Theory of Relativity</p>
</section>
</section>
<section id="summer-school-computational-neuroscience" class="level3">
<h3 data-anchor-id="summer-school-computational-neuroscience">🟩 Summer School (Computational Neuroscience)</h3>
<section id="neuromatch-academy-jun-2022---jul-2022-remote" class="level4">
<h4 data-anchor-id="neuromatch-academy-jun-2022---jul-2022-remote">🏛️ Neuromatch Academy | 🗓️ Jun 2022 - Jul 2022 | 🗺️ Remote</h4>
<hr>
</section>
</section>
</section>
<section id="projects" class="level2">
<h2 data-anchor-id="projects">📦️ Projects</h2>
<section id="functional-connectivity-differences-between-ecog-signals-during-motor-movement-vs.-motor-imagery" class="level4">
<h4 data-anchor-id="functional-connectivity-differences-between-ecog-signals-during-motor-movement-vs.-motor-imagery">🟧 <em>Functional connectivity differences between ECoG signals during motor movement vs.&nbsp;motor imagery</em></h4>
</section>
<section id="neuromatch-academy-summer-school-in-computational-neuroscience" class="level4">
<h4 data-anchor-id="neuromatch-academy-summer-school-in-computational-neuroscience">🏛️ Neuromatch Academy Summer School in Computational Neuroscience</h4>
<section id="jun-2022---jul-2022-link" class="level5">
<h5 data-anchor-id="jun-2022---jul-2022-link">🗓️ Jun 2022 - Jul 2022 | 🔗 <a href="https://github.com/ghosh-r/functional-connectivity-motor-imagery">Link ➡️</a></h5>
<ul>
<li>Human brain is responsible for both motor tasks, i.e.&nbsp;when actual movement of some body parts happen, and also for imagery tasks: when the person imagines a movement. This is a project that aims to find functional connectivity among brain areas in both imagined and real motor movements. This project also aims to find the similarity (or lack thereof) between real and imaginary movement in lower dimensional latent space of brain signals using Principal Component Analysis.</li>
</ul>
<p><strong>Skills</strong>: Python, PyTorch, Deep Learning, Computational Neuroscience, Team Work</p>
</section>
</section>
<section id="learn-jax-from-linear-regression-to-neural-networks" class="level3">
<h3 data-anchor-id="learn-jax-from-linear-regression-to-neural-networks">🟧 <em>Learn JAX: From Linear Regression to Neural Networks</em></h3>
<section id="personal-project" class="level4">
<h4 data-anchor-id="personal-project">🏛️ Personal Project</h4>
</section>
<section id="dec-2021---jan-2022-link" class="level4">
<h4 data-anchor-id="dec-2021---jan-2022-link">🗓️ Dec 2021 - Jan 2022 | 🔗 <a href="https://www.kaggle.com/code/truthr/jax-0">Link ➡️</a></h4>
<p>I introduce the JAX library for solving basic problems in Machine Learning. I explain everything so that a beginner in this framework will find it helpful. Introduced the functional programming paradigm for Deep Learning.</p>
<p>Won the Google Open Source Software Expert Prize</p>
<p><strong>Skills</strong>: JAX, Machine Learning, Deep Learning, Written Communication</p>
</section>
</section>
<section id="clip-for-satellite-images" class="level3">
<h3 data-anchor-id="clip-for-satellite-images">🟧 <em>CLIP for Satellite Images</em></h3>
<section id="hugging-face-x-google-cloud-hackathon" class="level4">
<h4 data-anchor-id="hugging-face-x-google-cloud-hackathon">🏛️ Hugging Face x Google Cloud Hackathon</h4>
</section>
<section id="jul-2021---sep-2021-link" class="level4">
<h4 data-anchor-id="jul-2021---sep-2021-link">🗓️ Jul 2021 - Sep 2021 | 🔗 <a href="https://github.com/arampacha/CLIP-rsicd">Link ➡️</a></h4>
<ul>
<li><p>This project is an Open-Source Deep Learning architecture that generates captions for satellite imagery.</p></li>
<li><p>We used transfer-learning to fine-tune OpenAI CLIP for satellite data.</p></li>
<li><p>Training was done for multiple hours on a TPUv3-8 enabled virtual machine provided by Google Cloud.</p></li>
<li><p>We used JAX/Flax and PyTorch for this model.</p></li>
<li><p>GitHub: https://github.com/arampacha/CLIP-rsicd</p></li>
<li><p>Demo: https://huggingface.co/spaces/sujitpal/clip-rsicd-demo</p></li>
<li><p>I worked on researching and applying different augmentation techniques that led to the improvement of the model.This project is an Open-Source Deep Learning architecture that generates captions for satellite imagery. We used transfer-learning to fine-tune OpenAI CLIP for satellite data. Training was done for multiple hours on a TPUv3-8 enabled virtual machine provided by Google Cloud. We used JAX/Flax and PyTorch for this model.</p></li>
</ul>
<p><strong>Skills</strong>: Transfer Learning, Deep Learning, Computer Vision, Linux, Jupyter Notebook</p>
</section>
</section>
<section id="dalle-mini" class="level3">
<h3 data-anchor-id="dalle-mini">🟧 <em>DALL·E Mini</em></h3>
<section id="hugging-face-x-google-cloud-hackathon-1" class="level4">
<h4 data-anchor-id="hugging-face-x-google-cloud-hackathon-1">🏛️ Hugging Face x Google Cloud Hackathon</h4>
</section>
<section id="jul-2021---sep-2021-link-1" class="level4">
<h4 data-anchor-id="jul-2021---sep-2021-link-1">🗓️ Jul 2021 - Sep 2021 | 🔗 <a href="https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA">Link ➡️</a></h4>
<ul>
<li><p>This project is an Open-Source Deep Learning architecture that generates images from a given text prompt. This implements the functionality of OpenAI’s DALL-E architecture, but with a 27x smaller model.</p></li>
<li><p>A BART autoregressive model was used to process and generate text, and a VQGAN to generate the images. Then we used a pre-trained CLIP model from OpenAI to rank the generated images.</p></li>
<li><p>Training was done for 70 hours on a TPUv3-8 enabled virtual machine provided by Google Cloud.</p></li>
<li><p>We used JAX/Flax and PyTorch for this model.</p></li>
<li><p>GitHub: https://github.com/borisdayma/dalle-mini</p></li>
<li><p>Demo: https://huggingface.co/spaces/flax-community/dalle-mini</p></li>
</ul>
<p><strong>Skills</strong>: Deep Learning, Linux, Google Cloud Platform, JAX, Flax, Team Work</p>
</section>
</section>
<section id="folk.ai-classifying-between-two-folk-dance-forms-of-india-using-deep-learning" class="level3">
<h3 data-anchor-id="folk.ai-classifying-between-two-folk-dance-forms-of-india-using-deep-learning">🟧 <em>Folk.AI: Classifying Between Two Folk Dance Forms of India Using Deep Learning</em></h3>
<section id="personal-project-during-taking-the-fast.ai-mooc" class="level4">
<h4 data-anchor-id="personal-project-during-taking-the-fast.ai-mooc">🏛️ Personal Project during taking the fast.ai MOOC</h4>
</section>
<section id="jul-2020---aug-2020-link" class="level4">
<h4 data-anchor-id="jul-2020---aug-2020-link">🗓️ Jul 2020 - Aug 2020 | 🔗 <a href="https://github.com/ghosh-r/folkAI">Link ➡️</a></h4>
<ul>
<li><p>Trained a Convolutional Neural Network with ResNet-34 leveraging transfer learning. Deployed the model as a web app for inference.</p></li>
<li><p>This app distinguishes between Kathakali and Chhau- two classical dance forms of India.Trained a Convolutional Neural Network with ResNet-34 leveraging transfer learning. Deployed the model as a web app for inference. GitHub- https://github.com/ghosh-r/folkAI This app distinguishes between Kathakali and Chhau- two classical dance forms of India.</p></li>
</ul>
<p><strong>Skills</strong>: Transfer Learning, Deep Learning, Computer Vision</p>
</section>
</section>
<section id="investing-in-a-new-eatery-in-california-a-data-driven-approach" class="level3">
<h3 data-anchor-id="investing-in-a-new-eatery-in-california-a-data-driven-approach">🟧 <em>Investing in A New Eatery in California: A Data Driven Approach</em></h3>
<section id="personal-project-for-ibm-data-science-professional-certificate" class="level4">
<h4 data-anchor-id="personal-project-for-ibm-data-science-professional-certificate">🏛️ Personal Project for IBM Data Science Professional Certificate</h4>
</section>
<section id="jul-2020---jul-2020-link" class="level4">
<h4 data-anchor-id="jul-2020---jul-2020-link">🗓️ Jul 2020 - Jul 2020 | 🔗 <a href="https://github.com/truth-r/Coursera_Capstone">Link ➡️</a></h4>
<ul>
<li><p>Applied KMeans Clustering algorithm to cluster counties of California, to look for and recommend new investment opportunities for investors looking to fund new eateries in California City.</p></li>
<li><p>Evaluated feature correlation through the Pearson Coefficient, and evaluated model through elbow method.</p></li>
<li><p>Final Report Link: https://github.com/ghosh-r/California_Eatery/blob/master/final_deliverables/capstone_project_final_report.pdf</p></li>
</ul>
<p><strong>Skills</strong>: Machine Learning, Data Science, Python, Scikit-Learn, Written Communication</p>
</section>
</section>
<section id="free-bengali-poetry-dataset-project" class="level3">
<h3 data-anchor-id="free-bengali-poetry-dataset-project">🟧 <em>Free Bengali Poetry</em> (Dataset project)</h3>
<section id="personal-project-1" class="level4">
<h4 data-anchor-id="personal-project-1">🏛️ Personal Project</h4>
</section>
<section id="jul-2021-link" class="level4">
<h4 data-anchor-id="jul-2021-link">🗓️ Jul 2021 | 🔗 <a href="https://www.kaggle.com/truthr/free-bengali-poetry">Link ➡️</a></h4>
<ul>
<li><p>I scraped about 2,700 copyright-free Bengali poems from the web and made them available under a permissive license. The intention of the project is to provide a freely available, well-structured dataset for downstream tasks of pre-trained language models, such as poetry generation.</p></li>
<li><p>This dataset is ideal for training language models to generate prose with pre-trained language models such as GPT-2, GPT-J, etc.</p></li>
<li><p>DOI: 10.34740/KAGGLE/DSV/2400728</p></li>
</ul>
<p><strong>Skills</strong>: Linux, Python, Web Scraping</p>
</section>
</section>
<section id="bengali-mnist-dataset-project" class="level3">
<h3 data-anchor-id="bengali-mnist-dataset-project">🟧 <em>Bengali-MNIST</em> (Dataset Project)</h3>
</section>
<section id="personal-project-2" class="level3">
<h3 data-anchor-id="personal-project-2">🏛️ Personal Project</h3>
<section id="mar-2021-link" class="level4">
<h4 data-anchor-id="mar-2021-link">🗓️ Mar 2021 | 🔗 <a href="https://www.kaggle.com/truthr/banglamnist">Link ➡️</a></h4>
<ul>
<li>Created a Dataset containing 70,000 images from an existing database so that it can be used for a seamless introduction to Vision, and can be used to solve commercial problems involving Bengali handwritten digits.</li>
</ul>
<p><strong>Skills</strong>: Python, Linux</p>
<hr>
</section>
</section>
</section>
<section id="honors-and-awards" class="level2">
<h2 data-anchor-id="honors-and-awards">🏅 Honors and Awards</h2>
<section id="winner-of-google-open-source-software-expert-prize" class="level3">
<h3 data-anchor-id="winner-of-google-open-source-software-expert-prize">🏆️ Winner of Google Open Source Software Expert Prize</h3>
<section id="googlekaggle" class="level4">
<h4 data-anchor-id="googlekaggle">🏛️ Google/Kaggle</h4>
</section>
<section id="apr-2022-link" class="level4">
<h4 data-anchor-id="apr-2022-link">🗓️ Apr 2022 | 🔗 <a href="https://archive.ph/WI8sS">Link ➡️</a></h4>
<ul>
<li>In this world-wide competition, I was awarded the prize along with two others for demonstrating expertise in Google’s Open Source software JAX and communicating my knowledge.</li>
</ul>
</section>
</section>
<section id="st-place-in-jaxflax-deep-learning-community-event" class="level3">
<h3 data-anchor-id="st-place-in-jaxflax-deep-learning-community-event">🏆️ 1st Place in JAX/Flax Deep Learning Community Event</h3>
<section id="hugging-face-x-google-cloud" class="level4">
<h4 data-anchor-id="hugging-face-x-google-cloud">🏛️ Hugging Face x Google Cloud</h4>
</section>
<section id="jul-2021-link-1" class="level4">
<h4 data-anchor-id="jul-2021-link-1">🗓️ Jul 2021 | 🔗 <a href="https://huggingface.co/spaces/flax-community/dalle-mini">Link ➡️</a></h4>
<ul>
<li><p>80+ Teams of about 800 people took part in this competition, and among ~50 final projects, our project was picked as the top one.</p></li>
<li><p>Our team consisted of a Software Engineer, two ML Engineers, three Ph.D.&nbsp;Students, and two undergraduate students.</p></li>
<li><p>We built an Open Source version of OpenAI’s Dall-E Mini, that generates images from text. We used JAX/Flax as our framework, trained on Cloud TPU-VMs with TPUv3-8s. We used a VQGAN + BART architecture, and CLIP to rank generated images.</p></li>
<li><p>I personally worked on sequence generation using BART and created part of the model front-end using Streamlit. Actively took part in all other aspects of the project.</p></li>
<li><p>On the Jury were Ross Wightman (Investor, DL Library maintainer), Asish Vaswani (of Transformers), Niki Parmar (Research Scientist, Google Brain), and Thomas Wolf (CSO of Hugging Face).</p></li>
<li><p>GitHub: https://github.com/borisdayma/dalle-mini</p></li>
<li><p>Report: https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini–Vmlldzo4NjIxODA</p></li>
</ul>
</section>
</section>
<section id="rd-place-in-jaxflax-deep-learning-community-event-organized-by-hugging-face-and-google-cloud" class="level3">
<h3 data-anchor-id="rd-place-in-jaxflax-deep-learning-community-event-organized-by-hugging-face-and-google-cloud">🏆️ 3rd Place in JAX/Flax Deep Learning Community Event Organized by Hugging Face and Google Cloud</h3>
<section id="hugging-face-x-google-cloud-1" class="level4">
<h4 data-anchor-id="hugging-face-x-google-cloud-1">🏛️ Hugging Face x Google Cloud</h4>
</section>
<section id="jul-2021-link-2" class="level4">
<h4 data-anchor-id="jul-2021-link-2">🗓️ Jul 2021 | 🔗 <a href="https://lnkd.in/eFKguYM">Link ➡️</a></h4>
<ul>
<li><p>80+ Teams of about 800 people took part in this competition, and among ~50 final projects, our project was picked for third place.</p></li>
<li><p>We built an Open Source model for captioning satellite images by fine-tuning CLIP with satellite image data (RSICD dataset). We expect it to be used in natural disaster management, climate monitoring, and defense among other uses.</p></li>
<li><p>We used JAX/Flax as our framework, trained on Cloud TPU-VMs with one TPUv3-8.</p></li>
<li><p>I personally worked on data augmentation techniques for the images in the dataset for improving the accuracy score.</p></li>
<li><p>On the Jury were Ross Wightman (Investor, DL Library maintainer), Ashish Vaswani (of Transformers fame), Niki Parmar (Research Scientist, Google Brain), and Thomas Wolf (CSO, Hugging Face).</p></li>
<li><p>GitHub: https://lnkd.in/eeWQBiX</p></li>
<li><p>Report: https://lnkd.in/en74Mmk</p></li>
</ul>
</section>
</section>
<section id="best-speaker-of-the-legislative-assembly-in-youth-parliament-competition-district-level" class="level3">
<h3 data-anchor-id="best-speaker-of-the-legislative-assembly-in-youth-parliament-competition-district-level">🏆️ “Best Speaker of The Legislative Assembly” in Youth Parliament Competition, District Level</h3>
<section id="department-of-parliamentary-affairs-government-of-west-bengal" class="level4">
<h4 data-anchor-id="department-of-parliamentary-affairs-government-of-west-bengal">🏛️ Department of Parliamentary Affairs, Government of West Bengal</h4>
</section>
<section id="dec-2015-link" class="level4">
<h4 data-anchor-id="dec-2015-link">🗓️ Dec 2015 | 🔗 <a href="https://www.dropbox.com/s/n5kib4j79b0jpa6/photo_2020-06-26_13-11-24.jpg">Link ➡️</a></h4>
<ul>
<li><p>Was awarded the the “Best Speaker of Legislative Assembly” award in district level of Youth Parliament Competition in (then undivided) Burdwan District, West Bengal. Received certificate signed by the Hon’ble Minister-in-Charge of Departments of Parliamentary Affairs, School Education and Higher Education, Government of West Bengal and Shri Basudeb Banerjee, I.A.S, Additional Chief Secretary, Home &amp; Parliamentary Affairs Department, Government of West Bengal.</p></li>
<li><p>Youth Parliament Competition is a Government funded competition to grow awarness about Parliamentary Democratic process, rules and decorum among school students.</p></li>
<li><p>My school stood first at the block level, and I was awarded the same award in the Block level and qualified to District level, and received the award.</p></li>
</ul>
</section>
</section>
<section id="rd-place-in-district-level-student-youth-science-fair" class="level3">
<h3 data-anchor-id="rd-place-in-district-level-student-youth-science-fair">🏆️ 3rd Place in District Level Student-Youth Science Fair</h3>
<section id="department-of-youth-services-government-of-west-bengal" class="level4">
<h4 data-anchor-id="department-of-youth-services-government-of-west-bengal">🏛️ Department of Youth Services, Government of West Bengal</h4>
</section>
<section id="sep-2015-link" class="level4">
<h4 data-anchor-id="sep-2015-link">🗓️ Sep 2015 | 🔗 <a href="https://www.dropbox.com/s/n7t7jjt0t5azi5j/photo_2020-06-26_13-15-15.jpg">Link ➡️</a></h4>
<ul>
<li><p>Designed a model of a stradling bus, and discussed on its logistics and was awarded 3rd Place in District Level (then undivided) Burdwan District.</p></li>
<li><p>And participated in State Level of the Competition.</p></li>
</ul>
<hr>
</section>
</section>
</section>
<section id="publications" class="level2">
<h2 data-anchor-id="publications">📜 Publications</h2>
<section id="complete-introductory-guide-to-speech-to-text-with-transformers" class="level3">
<h3 data-anchor-id="complete-introductory-guide-to-speech-to-text-with-transformers">📜 <em>Complete Introductory Guide to Speech to Text with Transformers</em></h3>
<section id="analytics-vidhya" class="level4">
<h4 data-anchor-id="analytics-vidhya">🏛️ Analytics Vidhya</h4>
</section>
<section id="jul-2023-link" class="level4">
<h4 data-anchor-id="jul-2023-link">🗓️ Jul 2023 | 🔗 <a href="https://www.analyticsvidhya.com/blog/2023/07/speech-to-text-with-transformers">Link ➡️</a></h4>
<ul>
<li><p>Wrote an introductory guide to using Transformers models for solving audio-related problems.</p></li>
<li><p>It is very practical and one can get started with Audio Machine Learning right away after reading this blog. This also teaches how to use Hugging Face to find models, datasets, and how to use them to solve one’s own problems.</p></li>
</ul>
</section>
</section>
<section id="non-linear-dynamics-through-linear-algebraic-lenses-attempting-to-learn-the-trajectories-of-the-logistic-map-with-artificial-neural-networks" class="level3">
<h3 data-anchor-id="non-linear-dynamics-through-linear-algebraic-lenses-attempting-to-learn-the-trajectories-of-the-logistic-map-with-artificial-neural-networks">📜 <em>Non-Linear Dynamics Through Linear Algebraic Lenses: Attempting to Learn the Trajectories of the Logistic Map with Artificial Neural Networks</em></h3>
<section id="masters-thesis-published-in-zenodo" class="level4">
<h4 data-anchor-id="masters-thesis-published-in-zenodo">🏛️ Master’s Thesis published in Zenodo</h4>
</section>
<section id="apr-2023-link" class="level4">
<h4 data-anchor-id="apr-2023-link">🗓️ Apr 2023 | 🔗 <a href="https://zenodo.org/record/7840239">Link ➡️</a></h4>
<ul>
<li><p>To automatically learn the behavior of trajectories of a map in Non-Linear Dynamics- the Logistic Map, Deep Neural Networks have been trained. Different iterates of the Logistic Map have been generated and models have been fit to them to test the learning capabilities of Neural Networks under such scenario. This paper examines the capability of Neural Networks to learn the dynamics of a system that can be modeled with the Logistic Map.</p></li>
<li><p>keywords- Non-Linear Dynamics, Deep Learning, Artificial Neural Networks, Physics, Computational Mathematics, Logistic Map</p></li>
</ul>
</section>
</section>
<section id="best-podcasts-for-machine-learning" class="level3">
<h3 data-anchor-id="best-podcasts-for-machine-learning">📜 <em>Best Podcasts for Machine Learning</em></h3>
<section id="kdnuggets" class="level4">
<h4 data-anchor-id="kdnuggets">🏛️ KDNuggets</h4>
</section>
<section id="apr-2021-link" class="level4">
<h4 data-anchor-id="apr-2021-link">🗓️ Apr 2021 | 🔗 <a href="https://www.kdnuggets.com/2021/04/best-podcasts-machine-learning.html">Link ➡️</a></h4>
</section>
</section>
<section id="taking-julia-for-a-test-drive-my-first-encounter-with-julia" class="level3">
<h3 data-anchor-id="taking-julia-for-a-test-drive-my-first-encounter-with-julia">📜 <em>TAKING JULIA FOR A TEST DRIVE: My First Encounter With Julia</em></h3>
<section id="towards-data-science" class="level4">
<h4 data-anchor-id="towards-data-science">🏛️ Towards Data Science</h4>
</section>
<section id="sep-2020-link" class="level4">
<h4 data-anchor-id="sep-2020-link">🗓️ Sep 2020 | 🔗 <a href="https://towardsdatascience.com/my-first-encounter-with-julia-15777c6189f9">Link ➡️</a></h4>
</section>
</section>
<section id="how-much-math-do-you-need-to-know-to-get-started-with-data-science-a-clear-straightforward-answer" class="level3">
<h3 data-anchor-id="how-much-math-do-you-need-to-know-to-get-started-with-data-science-a-clear-straightforward-answer">📜 <em>How Much Math Do You Need to Know to Get Started with Data Science? A Clear, Straightforward Answer</em></h3>
<section id="towards-data-science-1" class="level4">
<h4 data-anchor-id="towards-data-science-1">🏛️ Towards Data Science</h4>
</section>
<section id="jul-2020-link" class="level4">
<h4 data-anchor-id="jul-2020-link">🗓️ Jul 2020 | <a href="https://towardsdatascience.com/how-much-math-do-you-need-to-know-to-get-started-with-data-science-789b24d212fc">Link ➡️</a></h4>
<hr>
</section>
</section>
</section>
<section id="volunteering-experiences" class="level2">
<h2 data-anchor-id="volunteering-experiences">Volunteering Experiences</h2>
<section id="data-contributor" class="level3">
<h3 data-anchor-id="data-contributor">🌱 Data Contributor</h3>
<section id="mozilla-mar-2021---mar-2022" class="level4">
<h4 data-anchor-id="mozilla-mar-2021---mar-2022">🏛️ Mozilla | 🗓️ Mar 2021 - Mar 2022</h4>
<p>I recorded my voice and validates others’ for creating the Mozilla Common Voice Dataset. I was involved in five languages- Bengali, English, Spanish, Hindi, and German.</p>
</section>
</section>
<section id="mentor" class="level3">
<h3 data-anchor-id="mentor">🌱 Mentor</h3>
<section id="code-school-by-giles-mcmullen-jul-2021---present" class="level4">
<h4 data-anchor-id="code-school-by-giles-mcmullen-jul-2021---present">🏛️ Code School by Giles Mcmullen | 🗓️ Jul 2021 - Present</h4>
<ul>
<li>I help answer questions from beginners getting into programming and learning Data Science. I also guide beginners about programming languages, problem solving skills, tools, and other related things about programming and Data Science.</li>
</ul>
</section>
</section>
<section id="volunteer" class="level3">
<h3 data-anchor-id="volunteer">🌱 Volunteer</h3>
<section id="porichoy-jan-2015---jan-2017" class="level4">
<h4 data-anchor-id="porichoy-jan-2015---jan-2017">🏛️ Porichoy | 🗓️ Jan 2015 - Jan 2017</h4>
<ul>
<li>Served as a volunteer in Porichoy, a local group of volunteers aimed to serve the less fortunate after natural disasters and helping in education of children from economically challenged families. I mainly worked in rehabilitation after flood as a part of a team and organised cultural events.</li>
</ul>
</section>
</section>
<section id="mentor-of-youth-parliament-competition" class="level3">
<h3 data-anchor-id="mentor-of-youth-parliament-competition">🌱 Mentor of Youth Parliament Competition</h3>
<section id="dainhat-high-school-jul-2022---sep-2022" class="level4">
<h4 data-anchor-id="dainhat-high-school-jul-2022---sep-2022">🏛️ Dainhat High School | 🗓️ Jul 2022 - Sep 2022</h4>
<ul>
<li><p>Trained a group of fifteen high school students in Youth Parliament Competition.</p></li>
<li><p>Taught them about government, state-level polity, and conducts of Vidhan Sabha (State Legisslative Assembly)</p></li>
<li><p>Helped train them in speech delivery, acting, etc.</p></li>
<li><p>Helped write the script of 45 minute run- many additions, full editing, and wrote all English dialogues.</p></li>
<li><p>In the first competition, held at the level of Municipality, they won the First place beating three other schools.</p></li>
<li><p>In the next level, they won the Third place competing with 29 other schools in the District Level.</p></li>
</ul>
</section>
</section>
<section id="language-and-culture-volunteer" class="level3">
<h3 data-anchor-id="language-and-culture-volunteer">🌱 Language and Culture Volunteer</h3>
<section id="project-bhasha-jan-2019---feb-2021" class="level4">
<h4 data-anchor-id="project-bhasha-jan-2019---feb-2021">🏛️ Project Bhasha | 🗓️ Jan 2019 - Feb 2021</h4>
<ul>
<li>Project Bhasha was aimed at creating a website and a community around it to teach Bengali to foreigners. We took a broader approach to teach culture as well as the language. My role was to write articles on Bengali art, culture, language, and literature. I also oversaw some aspects of the overall strategy, pedagogy, etc.</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="hobbies" class="level2">
<h2 data-anchor-id="hobbies">🤸‍♂️ Hobbies</h2>
<p>Reading books, swimming, playing the piano, narrating stories, etc.</p>


</section>
</section>
</main> 
  <hr class="about-sep">
   <div class="about-links">
  <a href="https://twitter.com/AllesistKode" class="about-link" rel="" target="">
    <i class="bi bi-twitter"></i>
     <span class="about-link-text">Twitter</span>
  </a>
  <a href="https://linkedin.com/in/ritobrata-ghosh" class="about-link" rel="" target="">
    <i class="bi bi-linkedin"></i>
     <span class="about-link-text">LinkedIn</span>
  </a>
  <a href="https://github.com/ritog" class="about-link" rel="" target="">
    <i class="bi bi-github"></i>
     <span class="about-link-text">Github</span>
  </a>
</div>
</div>
 <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'alternate';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>